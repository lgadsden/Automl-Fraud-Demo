{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Financial Fraud using AutoML Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the needed python libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import automl_v1beta1 as automl\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import google.cloud.automl_v1beta1.proto.data_types_pb2 as data_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter Variables used for the Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter GCP ProjectID\n",
    "PROJECT_ID =   # e.g. \"fraud-demo-sled\"\n",
    "\n",
    "# enter compute region \n",
    "COMPUTE_REGION = \"us-central1\" #only us-central1 is supported for now\n",
    "\n",
    "BQ_DATASET_NAME =  # e.g. \"fin_fraud_data\"\n",
    "\n",
    "BQ_FRAUD_TABLE_NAME =  # e.g. \"PS_2017\"\n",
    "\n",
    "main_table_name = '.'.join([PROJECT_ID, BQ_DATASET_NAME, BQ_FRAUD_TABLE_NAME])\n",
    "\n",
    "training_table_name = '.'.join([PROJECT_ID, BQ_DATASET_NAME, \"training\"])\n",
    "\n",
    "prediction_table_name = '.'.join([PROJECT_ID, BQ_DATASET_NAME, \"actual\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Bigquery Table to be imported into AutoML Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to Bigquery Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes: Fraud cases are very rare. In this dataset there are 6,362,620 transactions. Only 8,213 are fraud.** <br>\n",
    "This means that **99.87%** of transactions are not fraud. If we were to build a model and predict \"not fraud\" every time, that model will have a **\"99.87%\" accuracy!!!**. That is very accurate, but it would not be useful for our case. <br> \n",
    "If we were to leave a model with it's default settings, the model would predict that everything is \"not fraud\" by default. <br>\n",
    "In order to account for the rare fraud occurances, we can either:\n",
    "- **Random Oversampling:** create duplicates of of the fraud cases (to get close to the same number of not fraud cases) \n",
    "- **Random Undersampling:** remove \"not fraud\" cases so that the fraud and not fraud cases are close to even\n",
    "- **Give rare case higher weight:** add a a weight to the fraud cases so that the model views them as more important <br>\n",
    "\n",
    "I thought that the number disparity between fraud and not fraud were too great to over or undersample. If we oversampled the ML model may see the same cases enough that it would identify those exact features as being fraudlent (i.e. a transaction of $1,334 is always fraud because the model has see it 1,000 times). While I thought that undersampling would lose too much data (we would go from 6,000,000 cases to less than 20,000. I ended up weighing cases identified as fraud at a much higher rate to tell the ML model that there will be a *big penealty for missing a fraudulent transaction* as compared to getting a \"not fraud\" wrong. <br>\n",
    "\n",
    "The proportion of fraud to not fraud is 773.7. To keep it simple, I weigh all fraud cases as 800 in this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the dataset, the max step (number of hours) is 743. Since the steps move toward the future (0 hours to 743 hours), I decided that it was best to split the data in a way that train to predict future events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step = 743"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split and Weight columns are created below** <br>\n",
    "\n",
    "**The dataset is split in four ways:**\\\n",
    "**1. Train:** The first 70% of hours data is our training set\\\n",
    "**2. Validation:** the next 10% of hours is our validation set\\\n",
    "**3. Test:** the next 10% of hours is our test set\\\n",
    "**4. Prediction:** The last 10% of hours is not used by the model, but instead used by us for prediction <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = training_table_name\n",
    "job_config = bigquery.QueryJobConfig(destination=table_id)\n",
    "\n",
    "sql = \"\"\"SELECT\n",
    "  CASE\n",
    "    WHEN step < CEIL({MAX_STEP}*.70) THEN \"TRAIN\"\n",
    "    WHEN step < CEIL({MAX_STEP}*.80) AND step >= CEIL({MAX_STEP}*.70) THEN \"VALIDATE\"\n",
    "    WHEN step < CEIL({MAX_STEP}*.90) AND step >= CEIL({MAX_STEP}*.80) THEN \"TEST\" END as split,\n",
    "  CASE\n",
    "    WHEN isfraud = 1 THEN 800\n",
    "    WHEN isfraud = 0 THEN 1\n",
    "    END as weight\n",
    "    , \n",
    "    *\n",
    "FROM\n",
    "  `{MAIN_TABLE}`\n",
    "WHERE step < CEIL({MAX_STEP}*.90)\n",
    "\"\"\".format(MAX_STEP=max_step,MAIN_TABLE = main_table_name)\n",
    "\n",
    "\n",
    "# Start the query, passing in the extra configuration.\n",
    "query_job = client.query(sql, job_config=job_config)  # Make an API request.\n",
    "query_job.result()  # Wait for the job to complete.\n",
    "\n",
    "print(\"Query results loaded to the table {}\".format(table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = prediction_table_name\n",
    "job_config = bigquery.QueryJobConfig(destination=table_id)\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM\n",
    "  `{MAIN_TABLE}`\n",
    "WHERE step >= CEIL({MAX_STEP}*.90)\n",
    "\"\"\".format(MAX_STEP=max_step)\n",
    "\n",
    "# Start the query, passing in the extra configuration.\n",
    "query_job = client.query(sql, job_config=job_config)  # Make an API request.\n",
    "query_job.result()  # Wait for the job to complete.\n",
    "\n",
    "print(\"Query results loaded to the table {}\".format(table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model and Make Predictions with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to AutoML Tables Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_client = automl.TablesClient(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter AutoML dataset name\n",
    "DATASET_DISPLAY_NAME = \"fin_fraud_data\"\n",
    "\n",
    "# enter AutoML Model Display name\n",
    "MODEL_DISPLAY_NAME = \"fraud_detection_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create AutoML Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dset = tables_client.get_dataset(dataset_display_name= DATASET_DISPLAY_NAME)\n",
    "    print(\"dataset exist\")\n",
    "except: \n",
    "    dataset = tables_client.create_dataset(DATASET_DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the dataset from Bigquery** <br> Note: Datasets can also be imported from GCS (as a csv) <br>\n",
    "**The models take between 10-30 minutes to import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tables_client.import_data(\n",
    "    dataset_display_name= DATASET_DISPLAY_NAME \n",
    "    bigquery_input_uri=\"bq://\" + training_table_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tell AutoML Tables how to split the data into traning, validation, and tetsing by pointing it to the \"split\" column that we created earlier** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_client.set_test_train_column(dataset_display_name=DATASET_DISPLAY_NAME,column_spec_display_name=\"split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View Dataset Specs, Update any types that were imported incorrectly** <br>\n",
    "Exmaple: Chnage if a FLOAT was imported as a STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_spec = tables_client.get_dataset(dataset_display_name=DATASET_DISPLAY_NAME)\n",
    "\n",
    "list_table_specs_response= tables_client.list_table_specs(dataset_display_name = DATASET_DISPLAY_NAME)\n",
    "table_specs = [s for s in list_table_specs_response]\n",
    "\n",
    "# List column specs.\n",
    "list_column_specs_response = tables_client.list_column_specs(dataset_display_name= DATASET_DISPLAY_NAME)\n",
    "column_specs = {s.display_name: s for s in list_column_specs_response}\n",
    "\n",
    "# Print Features and data_type.\n",
    "features = [(key, data_types.TypeCode.Name(value.data_type.type_code)) \n",
    "            for key, value in column_specs.items()]\n",
    "print('Feature list:\\n')\n",
    "for feature in features:\n",
    "    print(feature[0],':', feature[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update the weight for transactions that were identified as Fraud!!!** <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_column_name = weight \n",
    "update_weight_column = tables_client.update_column_spec(\n",
    "    dataset_display_name= DATASET_DISPLAY_NAME\n",
    "    column_spec_display_name= weight_column_name,\n",
    "    type_code=\"FLOAT64\",\n",
    "    nullable=False)\n",
    "\n",
    "set_weight_column = tables_client.set_weight_column(dataset_display_name=DATASET_DISPLAY_NAME, column_spec_display_name= weight_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the target column**<br>\n",
    "The target column is IsFraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_target = tables_client.set_target_column(dataset_display_name=DATASET_DISPLAY_NAME, column_spec_display_name= \"isFraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model** <br>\n",
    "The minimum training time is 1 hour. The max is 10 hours. <br>\n",
    "Trianing should automatically stop at the time when more training does not improve accuracy <br>\n",
    "We use 2 hours for this demo (it cost around \\\\$40 to build) <br>\n",
    "**The model will take 2 hours to build! You must wait 2 hours for predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_hours = 2\n",
    "create_model = tables_client.create_model(model_display_name = MODEL_DISPLAY_NAME,\n",
    "                           dataset_display_name=DATASET_DISPLAY_NAME,\n",
    "                           train_budget_milli_node_hours= model_train_hours * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model can be seen in the model list when it is ready. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = tables_client.list_models()\n",
    "for i in model_list:\n",
    "    print(i.display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deploy Model**<br>\n",
    "Deployed models are only used for online prediction, but it take around 10 minutes to delpoy a model. Deploy now so that you can do the online predictions faster later.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dep_rep = tables_client.deploy_model(model_display_name=MODEL_DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Predictions\n",
    "**Predict a large number of transactions in batch** <br>\n",
    "- A model does not have to be deployed for \"batch\" predictions\n",
    "- Batch predictions cost less than online predictions\n",
    "- Batch predictions take around 2-5 minutes to return results, while online is real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_predict = tables_client.batch_predict(model_display_name= MODEL_DISPLAY_NAME,\n",
    "                            bigquery_input_uri= 'bq://' + prediction_table_name,\n",
    "                            bigquery_output_uri= 'bq://' + PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online (Real-time) Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill in inputs and make a prediction. This cell should return you will be able to view the raw output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"step\": 675, \"type\": \"Debit\",\n",
    "          \"amount\": 10000, \"nameOrig\": \"C12434555\",\n",
    "          \"oldbalanceOrg\": 10000, \"newbalanceOrig\": 0,\n",
    "          \"nameDest\": \"M12345544\", \"oldbalanceDest\": 10000,\n",
    "          \"newbalanceDest\": 0, \"isFlaggedFraud\": \"1\"}\n",
    "\n",
    "prediction = tables_client.predict(inputs=inputs, model_display_name= MODEL_DISPLAY_NAME)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The end user can choose what probablity theshold tha they want to act on. By default, many models say that some is true if the probability is more than 50%. In reality, the probabilites close to 50% are more ambiguous, while the ones closer to 0% or 100% are more certain.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_percent = round(prediction.payload[1].tables.score * 100, 2)\n",
    "print(\"The model predicts that there is a {}% chance that the transaction is fraudulent.\".format(prediction_percent) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
